{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qPrQevtVHfAa"
   },
   "source": [
    "# **RAG Application** with LangChain and HuggingFace LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cAz0poIYiyQF",
    "outputId": "234e6294-edc2-4aa8-fb7d-b5c6a399df56"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m41.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m42.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m32.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m57.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m76.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.5/19.5 MB\u001b[0m \u001b[31m68.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.2/284.2 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m63.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.5/16.5 MB\u001b[0m \u001b[31m75.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.6/65.6 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.4/119.4 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.6/201.6 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.2/71.2 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m77.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m453.1/453.1 kB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m309.7/309.7 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "# Install the necessary packages\n",
    "!pip install torch -q\n",
    "!pip install transformers -q\n",
    "!pip install numpy -q\n",
    "!pip install langchain -q\n",
    "!pip install langchain_community -q\n",
    "!pip install langchain-chroma -q\n",
    "!pip install sentence_transformers -q\n",
    "!pip install rank_bm25 -q\n",
    "!pip install pypdf -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E65a79ds-F3J",
    "outputId": "d2f2a0d1-6664-46b1-bc1c-cfd6893a0b7e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.9/72.9 MB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install bitsandbytes -q\n",
    "!pip install accelerate -q\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "mvtHhNb7LlLe"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from google.colab import userdata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "imsRWg7LHnfa"
   },
   "source": [
    "### Initialize HuggingFace LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JlJ6qI0xJBln"
   },
   "source": [
    "Model repo url: https://huggingface.co/mistralai/Mistral-7B-v0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 539,
     "referenced_widgets": [
      "85ded6ced6fb468d9d6b65704beda9bc",
      "1e4452f3a5894a89a61032d4091acddb",
      "3ec9496487804b24b1a277e48ccb070b",
      "3c94b8a15da24e1ba114ba27131a9527",
      "7e99240edf804c0fa1da659024820dcc",
      "1d20f4ae616b4a8a9cf8deea54c34b18",
      "546493e30dd54f92ad8fde653bda62b0",
      "81dd239fa6f047269e40555ab641c92f",
      "3975a382117a4564adad1481e34026e9",
      "b2ad02e79ca0438b8fbffa8898bc202c",
      "9ff7c57796b942269ee8a874d4bcc128",
      "a36de8406f2e4d0cb4c52a5b9cd9d1ce",
      "2e1fad42a3b34c00b9ea85e67be4efcd",
      "e12a25121ee040eeb4db40f1aa653b2c",
      "2295c0bd9049449897aac472a8d5e046",
      "e597d597e6764a74b31329be18985aa3",
      "811bbb71148d48708fa395371c8d16c7",
      "b69ef76121cb4e7c84c9ba2f82e1b7c4",
      "9f0432a169064c919f6f850a58541b82",
      "b8401940ed6e4b4c9972d22827f75875",
      "28fb555d1ee340d08e745ddd398f4ca4",
      "e41ebd5cb3524ef59ed5efaa890ab221",
      "39fc54cf91f7421e943c18b2ff3f7ceb",
      "ec90226af0af44d2a25048ac6c3fc798",
      "2ba6f569fe714baf8c27a7b76b55a3b1",
      "1d76522697df4056ba863dc9a0ba80c6",
      "e5733d6674ea4ef28c79ade2e669dcdb",
      "605dc86dd223428ea75855c3d158ac73",
      "40820364fbca4e06b4f38ffdc611e9b6",
      "c91ed484c31f4904922cbaba31ebb7f8",
      "759865c7dde64e73b59966173470bb97",
      "8a815b7900b740edbe06c92cd676334a",
      "308f0b32034c4d8ba5c35b316a330ea9",
      "147c1d3b5e514442b0a773df179019fa",
      "78e76f7f99ad4ad884e8202a01354394",
      "3aaa40db4ed04a81a2bf415bd68ac5d6",
      "cd2a073fd8a94378876e3824a4210dc4",
      "e0be55b5a4eb4575a785725fb1956f7b",
      "ed64f00de27a42d18b3ab221ee7fdbf1",
      "3a6351e3683b45938033f0ec9f442b50",
      "da8ad1eda8ff460195043e7acbefe46e",
      "254cd8f80f3447dcabe3fd510599eb34",
      "3294e475c3aa4d1e8b4e600399c94043",
      "8b9a4728fa76401baedf3c46c78a1437",
      "364f59d4cbd44d42aaf6eaa3e88824a3",
      "665a6049cb03446b8d23ce875833391a",
      "f70a8926f95e4608a34691e37d5126ec",
      "6aa3501ba0ff4df69921ebe2e74beffa",
      "e0c1ce50dedc4348b5c27ec9afacba93",
      "6844388e62e24c3dab26236739836d28",
      "c47dad73e09c4320b2737446c9102414",
      "3e4f0d87848047538cc4eb12979269d4",
      "3644164ccf7b4f2186bdbcb13544bd00",
      "3be23110d6454ebfb6a0afb3b2913481",
      "f65cbbe29dd045e79e01762907a3bfda",
      "a4212f0bb2d0402595f1c5eea6e48466",
      "cc0b2f52edd74e46811bd8e284b49946",
      "b6b536543c5d43a8b154e840581e3965",
      "685404f051b8438983bbc3d4d52e05ea",
      "72725619611648f49dd433276c3b18c9",
      "e2ec40da43f9435d95b38e3e3409983a",
      "20824e6d07844a10b4e70e6cb90f9377",
      "0d5963d1083a4e09adb72d7edc84bfb0",
      "97dd2d3324c241ee86e5a1b5b0ca0c7d",
      "891e258135b1481b8d678044cc963718",
      "502fe9166ab14a25a839b3e5f8450df7",
      "380c5234996343fcba4b1b4e8ed49f00",
      "9aa40dde2c0e4afc824d1a3d6c2fdf15",
      "f966c56cb5b740218d83a094725c6964",
      "96cb3f1e495a4f1fa88ef9f28b1eac26",
      "f34e1ffd8bfa49168847794fba86488b",
      "7dd2217cf5ca4451a2c95a81a03c6bfb",
      "e9ee063458f04c5586898f68961a7aeb",
      "1548799d4e9b459aa79b3e9ce2cec5f1",
      "90aa77fbf957432096e9a4d274118125",
      "c8c632094499464caf7512caa01ce179",
      "2c33aa88983144b494cff6cc7b88ab52",
      "fef00bd43dce4827a0ee6781b73dd71c",
      "0c8aa15734a84796a3903578c6448845",
      "3e252f74600d42a6a93ef24da6558ad5",
      "12fb7efd468a46f1b6e5c4523be2e5dc",
      "26eca72de0ca441794e0a3d1141f6bc3",
      "7dee1436f30c495ca2764fdfcf3071b8",
      "256eede4703848fb96fc339f8a442ce3",
      "f82c6749f1aa4e10809da7693a157293",
      "18cbd3194bed4a81924e3905473c3e14",
      "59add8fc3ee44887827905d58446f4b3",
      "68a521e3e2f3488283a0e24ddc01253f",
      "5d481828acbd457790f6563a1dd0f49b",
      "a0bf11b36e494502ac08e223b173c6f0",
      "04101b7803db46d59a0a9b5f1496fa66",
      "95c3d77dd1f346379fe38e63c530c275",
      "c719c7c286904dd68ce8f95215c7a5c3",
      "0741640d732e47c184bd04b5f6b58751",
      "32f7b6f6b49e4523b7682f993e2316ae",
      "4130f31bc06b4715922926903aa680e5",
      "d4222088be594da7a6d5f2eabcc0697e",
      "d639086d07ef4bb896e1607a2c96c1d5",
      "f8a1390860c84ebba09f1f3658ce6fd7",
      "4fd5b765e6694d14920c2212868ee7cd",
      "3613e5286b8a40c8a1e8e69854073f03",
      "da35b6ceef264adfb7f0949ec9dff870",
      "c845bb609620428494553894238d8e78",
      "d8db7c61b8444fedb7cc5616611bfd40",
      "772029297cb647e7b9bc0005c54164df",
      "181d08cbdb084e6c9351c914f9e71148",
      "377bf0a0e2344a2589bdd84100a9e841",
      "6452135050ed49cd93f725f96d288b5d",
      "e7f18ae8cc7645ccb761f247fde9437d",
      "097c72d07c6d488587b2f2c5ebdd656e"
     ]
    },
    "id": "CQco8KHsLsoE",
    "outputId": "3894914d-0607-49fd-e678-3c23374e3973"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85ded6ced6fb468d9d6b65704beda9bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a36de8406f2e4d0cb4c52a5b9cd9d1ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39fc54cf91f7421e943c18b2ff3f7ceb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/281 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "147c1d3b5e514442b0a773df179019fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "364f59d4cbd44d42aaf6eaa3e88824a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4212f0bb2d0402595f1c5eea6e48466",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "380c5234996343fcba4b1b4e8ed49f00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/9.95G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fef00bd43dce4827a0ee6781b73dd71c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/4.48G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d481828acbd457790f6563a1dd0f49b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fd5b765e6694d14920c2212868ee7cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/117 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "/tmp/ipython-input-4-1369386646.py:46: LangChainDeprecationWarning: The class `HuggingFacePipeline` was deprecated in LangChain 0.0.37 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFacePipeline``.\n",
      "  llm = HuggingFacePipeline(pipeline=pipe)\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "from langchain_community.llms import HuggingFacePipeline\n",
    "import torch\n",
    "import os\n",
    "\n",
    "# Set CUDA memory allocator config\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "\n",
    "# Define the model ID — you can still use a large one, but smaller models are safer\n",
    "model_id = \"tiiuae/falcon-7b-instruct\"  # OR try \"tiiuae/falcon-rw-1b\" for lighter usage\n",
    "\n",
    "# Get your API token\n",
    "huggingface_api_token = userdata.get('HUGGINGFACE_API_KEY')\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, token=huggingface_api_token)\n",
    "\n",
    "import gc\n",
    "import torch\n",
    "\n",
    "# Clear memory before loading model\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "# Load the quantized 4-bit model\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.float16,\n",
    "    load_in_4bit=True,  # <== THIS is the key\n",
    "    token=huggingface_api_token\n",
    ")\n",
    "\n",
    "# Create the inference pipeline\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_new_tokens=256,\n",
    "    do_sample=True,\n",
    "    temperature=0.1,\n",
    "    trust_remote_code=True,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "# Wrap into LangChain LLM\n",
    "llm = HuggingFacePipeline(pipeline=pipe)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YY_2RLpfHq5q"
   },
   "source": [
    "### Initialize Embedding Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YHF9sDROJOYA"
   },
   "source": [
    "Model url: https://sbert.net/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 425,
     "referenced_widgets": [
      "9efc73f60ae9401cb4325081bfa16f7e",
      "7325843729674a06b4c9bb6dbdadd960",
      "06943ba89e84495c8f63cc6b52558b30",
      "cbfa6bf9f9c34c88aad7025e76a2e59a",
      "8e1f080bfd6446038ac9a46015a437a6",
      "3d9e81bd3f394ef685e2aef5fc3c473e",
      "2a95e0d0e89b4a7498fb28e243090f85",
      "f664e0896f9e4640bc94662d0685e1db",
      "ff30e667b0ee415097bad3aaec033522",
      "ecfc75c5396943709aac9735840f4de4",
      "4ffe727925484afaacee166fcac24022",
      "eb6e466812a94ff79658ff0456a02ccf",
      "7226531a5d234c288c58b913ec9ee89b",
      "99ae410cb4324c42b90133f8d48f7a75",
      "e31f1952db2345a4b1a1e6b94c1df149",
      "dbe24c12530c4b4abb219ec22b0cf4b1",
      "6e12d6a5079b48de8207220810d0e749",
      "8f23fccbd1e64930ab5e1955d24aeba5",
      "a0fa542f05774ce3b7ee4d94c2337880",
      "5821d835aa0b461289a265b06cba8751",
      "8e738b6c02b841b9878617ec06710577",
      "62e84c5881174fc9b7c0e9a87a237b81",
      "1e3003c716c241a882dcad1811c541fb",
      "01d4713c0fdf4501aa281fa680ed61b6",
      "ce8f9d0355a94365b4c39957d586724e",
      "f6e2af9ed3584f3c877a1774add48e23",
      "6b8ef8d16fe445e9a3d2d84db2adaff8",
      "8c003acfffda4dad8de40811f840d6f0",
      "565fff22c6324de483671530d71c04b4",
      "8cb5688b100548f88ea7a7c8fb4bee06",
      "663eac4948844dca8c7f71880623c9cb",
      "25d9c24b55a24a45960e1a26c791d6e3",
      "4dcb0098732e4d459642537b3147c994",
      "c6045a900feb4529978b1b77f7ba57ce",
      "297bcd8efeed48b8ba96cc80b43f51e3",
      "b911b1edc6924559a9cc1f27a51f212c",
      "e3b3023230f0428a90fc41dac9b954f3",
      "71299236d8944c4da2880b6ead076292",
      "bfddd6218b6b4c4189375e30f5556323",
      "345cb684d9364a18823d76d453539bbb",
      "69e56af58c964493b6573ffef2b8cbe4",
      "d808b25e80be459f98556fa06b2bc948",
      "86483c92f8cd4b56b670376b632948f2",
      "3cfe7aa7d988447fb75d684d054c8356",
      "331c50f90571475eac638098a30a8cb9",
      "4f6a557f350b4f929fb1cb66b113e171",
      "a29e02abe3be47c59ad1d5846d663896",
      "a68235c4720f4854bc79d9e42834ecc3",
      "c06b9ad1122540e7b57bf28605627644",
      "795e934947034f089532f10e9528bdea",
      "f33649f2ceb44ad0a3b683254ed2d617",
      "a448f0cd94e643ad8081a875b61792b2",
      "efad8e2dcb954444ac8bd5b979d74080",
      "97b3cae78cb844bf8d268ce80dce238d",
      "a6e779c20d9d4c6095894720efce0e45",
      "30db3457f77243fc8e5c9375fb1728e1",
      "93e700b8d89947fa92c867df7f3cff0c",
      "58fef76155a64757b363b09699cbcf63",
      "d13d1bf5a27547009e94fce52f5ce7d7",
      "259670d3daf148d8a197a5c338fcc681",
      "beb1bbea8fb3412a992d4de70b7fd545",
      "922e5c72a565405b8c922245b27e99f5",
      "0cfb65733962479e976cec211324be15",
      "d34805b56eeb49a5a6b0b87392c44bbd",
      "31d4261dbbd544a99220acc44cdf3f58",
      "91aa388c493e4d4eace21e7f3694c4d1",
      "d5f8804a7f8449b6a58fb509aa07d73c",
      "0c303ee282de43999fcfcf48407629b2",
      "899e5bf8f57344fbbb5a52c2221f4097",
      "b5e13fce445141e6a5b6a98bc8e10505",
      "af1d4202c66b4f17a79d374e3acb1f0e",
      "7b1452682f0e4083b67eff23ea3540bd",
      "c495cb106c14450a9bdf46d8079e3974",
      "a16d073a9949445b83c61cdd1c110313",
      "e5e920dd9ad5435ba40cc207821b1593",
      "10c96f93cf294d9d9db7da27412e6eb5",
      "edc2e0492929495388e600dd88ec5575",
      "91c8a8a2f85a46b4accacdccb4d6cc00",
      "c4d4f112c79548be8df585afaf7122c9",
      "cf1dfa1b595b4fd6b506536f20b8a19f",
      "4122f18387ff49429583fbff408d0dea",
      "ca09edfe823d4a4cae80a27d4e05d21e",
      "cb6c1f2e72f9493aa7e72a8c06d58339",
      "76349e2154a249a6bf3312c78e7ef429",
      "e57b08d161064d31be4917aace48f637",
      "c7e50db8cb7047af804ae81478b07ede",
      "70dc7809faad40f39dfd65452ecd4918",
      "38f64ec581154af7b363572aa7b0e1c8",
      "327db6f0521649c99e811ccc74b375cc",
      "1516f06c4cbd4d208b958df2e1bc24ff",
      "502ca00366a9464f8983738ca6abd24a",
      "4de1be82a5334dd5b3a960f632cb0e06",
      "408cebad5ffe45b98ab2204d12a6a31f",
      "559dd726725b4307a2db7f74e66c06ee",
      "f845989e29184337af0ceabbbdcb87b0",
      "1f03a0177714433a950119d8a85e51b5",
      "99968ae15b86453f9ae2a5140ef5dd9e",
      "878fb1bb2c2f48aca5daec0bed183cce",
      "65ec4bf97cfe48289cec30608124ac6f",
      "a7b19d83b41040bd893ca4d81ab1cf16",
      "c3e09d5f26e64eb19a4c5f9eb409b9d4",
      "6eeeb7ae723545e18ab45272dd6afa8b",
      "b48b498502404d62969f0bce3ae1ced7",
      "8de7dd20dcfd4de4bcf13cae2c6d1590",
      "feac2c73f6e445de8455f81913d07d4c",
      "1b6aa571ae8c4c8ca923b27f77800fcb",
      "beccfb907fba4b34a43bcd7d417f7456",
      "086e8ff966854787a6a32a6fa99d3181",
      "18b41fb1066f40f19ca8a8c50475a72c",
      "e61cf2094afa4ec2b4d996d1f6de41c5",
      "5c061552a958474183a22b2c980b6daf",
      "1167aa29f88c4ceab5ead3c177dddc14",
      "d000e17eb1f547c58cbfa4efac49396a",
      "ce874084585345ae8d9d103ff2d42463",
      "b1d63b38280a43bfad7422b18507c9f1",
      "2e8c2a3ed37246b3b7167b1a11e13186",
      "a30689d0b9e64ac6b6cb36de14aa9afa",
      "6d2090cd57bc4853a10fd29a13a14a50",
      "5139f1adf1ea4fe182f01f6963b7cf62",
      "54f73eb953ca4980a4af3be3c219f7a4",
      "dbb778c9933f4102a385a903dddff989"
     ]
    },
    "id": "v5VIj7wtD85u",
    "outputId": "ac0121dc-4357-4120-e93e-f5970172cef1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipython-input-5-1742308964.py:3: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embedding_model = HuggingFaceEmbeddings(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9efc73f60ae9401cb4325081bfa16f7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb6e466812a94ff79658ff0456a02ccf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e3003c716c241a882dcad1811c541fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6045a900feb4529978b1b77f7ba57ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "331c50f90571475eac638098a30a8cb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30db3457f77243fc8e5c9375fb1728e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5f8804a7f8449b6a58fb509aa07d73c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91c8a8a2f85a46b4accacdccb4d6cc00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "327db6f0521649c99e811ccc74b375cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7b19d83b41040bd893ca4d81ab1cf16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c061552a958474183a22b2c980b6daf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "embedding_model = HuggingFaceEmbeddings(\n",
    "  model_name=\"sentence-transformers/all-mpnet-base-v2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uIowHT1AIk6g"
   },
   "source": [
    "### Initialize Output Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "ph6yJRAeI3Dg"
   },
   "outputs": [],
   "source": [
    "from langchain.schema.output_parser import StrOutputParser\n",
    "\n",
    "output_parser=StrOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MLPtLHuaHyDh"
   },
   "source": [
    "### Load PDF Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "FtE4Pcb_ElWT"
   },
   "outputs": [],
   "source": [
    "!pip install pypdf -qU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "wj8NjIe9ElTX"
   },
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "# Load the PDF document\n",
    "loader = PyPDFLoader(\"/content/lustraderm_company_profile.pdf\")\n",
    "\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2JaKCnaeElQQ",
    "outputId": "78ad30af-d12a-4584-f822-83ae0cae2ad9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MUpL3Z7BElNH",
    "outputId": "a1429b66-2652-4197-fb40-ce2c7d02ba7d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'producer': 'PyFPDF 1.7.2 http://pyfpdf.googlecode.com/', 'creator': 'PyPDF', 'creationdate': 'D:20250701105709', 'source': '/content/lustraderm_company_profile.pdf', 'total_pages': 2, 'page': 0, 'page_label': '1'}, page_content=\"LustraDerm Skincare Pvt Ltd\\nCompany Overview\\nFounded Year: 2014\\nFounder: Dr. Malini Jayawardena\\nCompany Type: Private Limited\\nHeadquarters: Colombo, Sri Lanka\\nEmail: contact@lustraderm.lk\\nWebsite: https://www.lustraderm.lk\\nMission & Vision\\nMission: To provide scientifically formulated, nature-inspired skincare solutions that are safe, effective, and\\naffordable.\\nVision: To become South Asia's leading provider of clean, dermatologically-approved skincare products by\\n2030.\\nProduct Portfolio\\n- HydraBoost Moisturizing Cream\\n- ClearGlow Acne Control Serum\\n- SPF 50+ Daily Shield Sunscreen\\n- GentleFoam Facial Cleanser\\n- Night Renew Retinol Cream\\nCertifications & Compliance\\n- Dermatologist-Tested\\n- Cruelty-Free Certified\\n- ISO 22716 Compliant (Cosmetic GMP)\\n- 100% Paraben-Free\\n- Made with Plant-Derived Ingredients\\nMarket Presence\\nCurrently operating in: Sri Lanka, India, Singapore, Malaysia, United Arab Emirates\\nResearch & Development\\nOur in-house R&D lab in Colombo develops every product under strict quality control. We partner with local\\nuniversities to research herbal extracts and their dermatological effects.\\nCorporate Social Responsibility (CSR)\")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7K9dWgI7H2fA"
   },
   "source": [
    "### Split Documents into Chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "qu4Ol5uEElKD"
   },
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Initialize the text splitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=400, chunk_overlap=50)\n",
    "\n",
    "# Split the documents into chunks\n",
    "splits = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OnX6N-TfE2x0",
    "outputId": "6b484279-e96b-40db-89e3-02a923b5841e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#number of chunks\n",
    "len(splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AelGC3MNTxNv",
    "outputId": "7364dd8d-7c0b-4dc7-855f-27cd93c50590"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'producer': 'PyFPDF 1.7.2 http://pyfpdf.googlecode.com/', 'creator': 'PyPDF', 'creationdate': 'D:20250701105709', 'source': '/content/lustraderm_company_profile.pdf', 'total_pages': 2, 'page': 0, 'page_label': '1'}, page_content='LustraDerm Skincare Pvt Ltd\\nCompany Overview\\nFounded Year: 2014\\nFounder: Dr. Malini Jayawardena\\nCompany Type: Private Limited\\nHeadquarters: Colombo, Sri Lanka\\nEmail: contact@lustraderm.lk\\nWebsite: https://www.lustraderm.lk\\nMission & Vision\\nMission: To provide scientifically formulated, nature-inspired skincare solutions that are safe, effective, and\\naffordable.')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splits[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "utzSuxMlyrmi"
   },
   "source": [
    "Parse the CSV File and Convert It to Text Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "VMfnorwDyoo6"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "# Load the CSV\n",
    "csv_path = \"/content/skincare_products_synthetic_50.csv\"  # Replace with actual path\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Convert each row into a text chunk\n",
    "csv_documents = []\n",
    "for i, row in df.iterrows():\n",
    "    content = f\"\"\"\n",
    "    Product Name: {row['product_name']}\n",
    "    Type: {row['product_type']} | Category: {row['category']}\n",
    "    Skin Type: {row['skin_type']} | Use Case: {row['use_case']}\n",
    "    Ingredients: {row['ingredients']}\n",
    "    Scent: {row['scent']} | Form: {row['product_form']} | Packaging: {row['packaging_type']}\n",
    "    SPF Rating: {row['spf_rating']} | Price: ${row['price_usd']}\n",
    "    Paraben Free: {row['paraben_free']} | Cruelty Free: {row['cruelty_free']}\n",
    "    Rating: {row['average_rating']} ({row['review_count']} reviews)\n",
    "    Availability: {row['stock_status']} | Launch Year: {row['launch_year']}\n",
    "    Tagline: {row['tagline']}\n",
    "    Keywords: {row['keywords']}\n",
    "    \"\"\"\n",
    "    csv_documents.append(Document(page_content=content, metadata={\"source\": \"csv\"}))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8QXX_0zdH7qw"
   },
   "source": [
    "### Create Vector Store and Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "5N_28g2TElG7"
   },
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "\n",
    "\n",
    "# Combine PDF and CSV documents\n",
    "all_docs = splits + csv_documents\n",
    "\n",
    "# Create vector store from both\n",
    "vectorstore = Chroma.from_documents(documents=all_docs, embedding=embedding_model)\n",
    "vectorstore_retriever = vectorstore.as_retriever(search_kwargs={\"k\": 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BQLZx07vjWMQ",
    "outputId": "fd9d1cef-6c66-45dd-a1aa-93db86f36f65"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['Chroma', 'HuggingFaceEmbeddings'], vectorstore=<langchain_chroma.vectorstores.Chroma object at 0x7d7163aa03d0>, search_kwargs={'k': 2})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorstore_retriever"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c6SEtNk0jJLw"
   },
   "source": [
    "## For more effectiveness create Hybrid search system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vs5My2ywjdSK"
   },
   "source": [
    "Create Keyword search retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "9xNeI8aZjrrY"
   },
   "outputs": [],
   "source": [
    "from langchain.retrievers import BM25Retriever\n",
    "\n",
    "keyword_retriever = BM25Retriever.from_documents(all_docs)\n",
    "\n",
    "keyword_retriever.k =  2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5waaDmpvj5y6",
    "outputId": "7a947eff-c177-4f65-b7fe-b5a2af595160"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BM25Retriever(vectorizer=<rank_bm25.BM25Okapi object at 0x7d71643e2d50>, k=2)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keyword_retriever"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6r3WEiPPj8lU"
   },
   "source": [
    "###Create Hybrid Search Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "9TVcLt52kCjQ"
   },
   "outputs": [],
   "source": [
    "from langchain.retrievers import EnsembleRetriever\n",
    "\n",
    "ensemble_retriever = EnsembleRetriever(retrievers = [vectorstore_retriever, keyword_retriever], weights = [0.5, 0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GgrYWpwRkSxN",
    "outputId": "ff772b63-87a2-472d-9235-04e280fa1da7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EnsembleRetriever(retrievers=[VectorStoreRetriever(tags=['Chroma', 'HuggingFaceEmbeddings'], vectorstore=<langchain_chroma.vectorstores.Chroma object at 0x7d7163aa03d0>, search_kwargs={'k': 2}), BM25Retriever(vectorizer=<rank_bm25.BM25Okapi object at 0x7d71643e2d50>, k=2)], weights=[0.5, 0.5])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_retriever"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NwmJ1WA-744q"
   },
   "source": [
    "Import and Initialize Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TWIHHtey717a",
    "outputId": "a0224f6f-f863-44f8-e1ac-dc83309f3b5c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipython-input-21-647733764.py:4: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory(\n"
     ]
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "# Add conversational memory to store user/assistant turns\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\",\n",
    "    return_messages=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PeZ-Mdj1ICp4"
   },
   "source": [
    "### Define Prompt Template"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qcvvDoaDmzn4"
   },
   "source": [
    "Try to develop the prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "YPIO8jBdmxKW"
   },
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "template = \"\"\"\n",
    "You are a helpful assistant. Use the conversation history and the provided context below to answer the user's question.\n",
    "\n",
    "{chat_history}\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "User: {query}\n",
    "Assistant:\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TrDIRXFXEk7D",
    "outputId": "02601fc2-0a9c-49fd-b4f3-197e61261fe4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['chat_history', 'context', 'query'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['chat_history', 'context', 'query'], input_types={}, partial_variables={}, template=\"\\nYou are a helpful assistant. Use the conversation history and the provided context below to answer the user's question.\\n\\n{chat_history}\\n\\nContext:\\n{context}\\n\\nUser: {query}\\nAssistant:\"), additional_kwargs={})])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7DuaAR7YIUvo"
   },
   "source": [
    "### Chain Retriever and Prompt Template with LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wn4Od1Xlwrc_"
   },
   "source": [
    "Then modify your RAG chain or prompt pipeline to use that instead of retriever.get_relevant_documents:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WM3vWb8vMs0E"
   },
   "source": [
    "optional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jdJTGARNpGCy"
   },
   "source": [
    "Create RAG Chain with Hybrid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "mQZSCVSmpDeg"
   },
   "outputs": [],
   "source": [
    "from langchain.schema.runnable import RunnableMap\n",
    "\n",
    "chain = (\n",
    "    RunnableMap({\n",
    "        \"context\": lambda x: ensemble_retriever.get_relevant_documents(x[\"query\"]),\n",
    "        \"query\": lambda x: x[\"query\"],\n",
    "        \"chat_history\": lambda x: memory.load_memory_variables({})[\"chat_history\"]\n",
    "    })\n",
    "    | prompt\n",
    "    | llm\n",
    "    | output_parser\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AvP5N4nuIIwQ"
   },
   "source": [
    "#### Invoke RAG Chain with Example Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VNtU1zuR8d_p",
    "outputId": "5d4d4bf0-f8d5-4eb4-843e-cf8ec8149ec3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You: is this company availavle cucumber eye gel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipython-input-24-1521216589.py:5: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  \"context\": lambda x: ensemble_retriever.get_relevant_documents(x[\"query\"]),\n",
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
      "/usr/local/lib/python3.11/dist-packages/bitsandbytes/nn/modules.py:457: UserWarning: Input type into Linear4bit is torch.float16, but bnb_4bit_compute_dtype=torch.float32 (default). This will lead to slow inference or training speed.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: Yes, the company is available.\n",
      "User\n",
      "You: what is price of it\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: The product is available for purchase at $25.46.\n",
      "You: what is the packaging type of that\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: The packaging type of the product is a jar.\n",
      "You: for what product you gave as product type is jar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: The product is a Hyaluronic Acid Moisturizer.\n",
      "User\n",
      "You: in this company available Hyaluronic Acid Moisturizer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: Yes, the company is available.\n",
      "User\n",
      "You: what are the ingredients of that  product\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: The product contains Hyaluronic Acid, Ceramides, and Lavender.\n",
      "User\n",
      "You: what is the price of that  product\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: The product is available for purchase at $25.46.\n",
      "You: is there any company contat details\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: Yes, there is a company contact details. The company name is LustraDerm Skincare Pvt Ltd and their contact details are as follows:\n",
      "\n",
      "Phone: +94 (0) 11 2 666 666\n",
      "\n",
      "Email: contact@lustraderm.lk\n",
      "\n",
      "Website: https://www.lustraderm.lk\n",
      "\n",
      "Is there anything else I can help you with?\n",
      "User\n",
      "You: exit\n",
      "Conversation ended.\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    try:\n",
    "        user_input = input(\"You: \").strip()\n",
    "        if user_input.lower() in [\"exit\", \"quit\"]:\n",
    "            print(\"Conversation ended.\")\n",
    "            break\n",
    "\n",
    "        # Invoke the conversational RAG chain\n",
    "        response = chain.invoke({\"query\": user_input})\n",
    "\n",
    "        # Clean the response: remove anything before \"Assistant:\" if it exists\n",
    "        if isinstance(response, str) and \"Assistant:\" in response:\n",
    "            response = response.split(\"Assistant:\")[-1].strip()\n",
    "        else:\n",
    "            response = response.strip()\n",
    "\n",
    "        print(\"Bot:\", response)\n",
    "\n",
    "\n",
    "        # Store the turn in memory\n",
    "        memory.save_context({\"input\": user_input}, {\"output\": response})\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nStopped by user.\")\n",
    "        break\n",
    "    except Exception as e:\n",
    "        print(\"Error:\", str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "0OV-GroAOKzK"
   },
   "outputs": [],
   "source": [
    "!pip install gradio -q\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YFPiXqmgOTx7"
   },
   "source": [
    "Define a Gradio Chat Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "s_V-YSCrOMzF"
   },
   "outputs": [],
   "source": [
    "chat_history_list = []\n",
    "\n",
    "def gradio_chatbot(user_input):\n",
    "    global chat_history_list\n",
    "\n",
    "    # Prepare input for the chain\n",
    "    response = chain.invoke({\"query\": user_input})\n",
    "\n",
    "    # Clean assistant response\n",
    "    if isinstance(response, str) and \"Assistant:\" in response:\n",
    "        response = response.split(\"Assistant:\")[-1].strip()\n",
    "    else:\n",
    "        response = response.strip()\n",
    "\n",
    "    # Save to memory for conversational context\n",
    "    memory.save_context({\"input\": user_input}, {\"output\": response})\n",
    "\n",
    "    # Append to chat history for Gradio UI\n",
    "    chat_history_list.append((user_input, response))\n",
    "\n",
    "    return \"\", chat_history_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vfp4hP16ORL6"
   },
   "source": [
    "Create Gradio Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 650
    },
    "id": "VrlN6dn4OO3l",
    "outputId": "c0520b9b-9e96-4c6d-aec3-b477681ce623"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipython-input-30-371637380.py:6: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
      "  chatbot = gr.Chatbot()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
      "* Running on public URL: https://412f751633b3c62297.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://412f751633b3c62297.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"## 💬 Skincare RAG Chatbot\")\n",
    "\n",
    "    chatbot = gr.Chatbot()\n",
    "    msg = gr.Textbox(placeholder=\"Ask me about the company or products...\")\n",
    "    clear = gr.Button(\"Clear\")\n",
    "\n",
    "    # Bind chatbot logic\n",
    "    msg.submit(gradio_chatbot, inputs=msg, outputs=[msg, chatbot])\n",
    "    clear.click(lambda: ([], []), None, outputs=[chatbot, msg])\n",
    "\n",
    "demo.launch(share=True)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
